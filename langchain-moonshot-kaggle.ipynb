{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7961451,"sourceType":"datasetVersion","datasetId":4683442}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-29T03:45:29.357310Z","iopub.execute_input":"2024-03-29T03:45:29.358697Z","iopub.status.idle":"2024-03-29T03:45:30.538538Z","shell.execute_reply.started":"2024-03-29T03:45:29.358658Z","shell.execute_reply":"2024-03-29T03:45:30.537077Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/langchain-moonshot-0-0-6/langchain_moonshot-0.0.6-py3-none-any.whl\n/kaggle/input/optimizers/Deep Optimizers.pdf\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras-core wurlitzer","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:45:30.540851Z","iopub.execute_input":"2024-03-29T03:45:30.541399Z","iopub.status.idle":"2024-03-29T03:45:49.319934Z","shell.execute_reply.started":"2024-03-29T03:45:30.541368Z","shell.execute_reply":"2024-03-29T03:45:49.317959Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting keras-core\n  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\nCollecting wurlitzer\n  Downloading wurlitzer-3.0.3-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.0.7)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core) (3.10.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.1.8)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.2)\nDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\nInstalling collected packages: wurlitzer, keras-core\nSuccessfully installed keras-core-0.1.7 wurlitzer-3.0.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install \"dill<0.3.2,>=0.3.1.1\"\n!pip install -U \"numpy<1.25.0,>=1.14.3\"\n!pip install --upgrade --quiet  langchain langchain-community","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:49:28.573983Z","iopub.execute_input":"2024-03-29T03:49:28.574443Z","iopub.status.idle":"2024-03-29T03:50:16.569692Z","shell.execute_reply.started":"2024-03-29T03:49:28.574410Z","shell.execute_reply":"2024-03-29T03:50:16.568360Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (0.3.1.1)\nRequirement already satisfied: numpy<1.25.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (1.24.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U /kaggle/input/langchain-moonshot-0-0-6/langchain_moonshot-0.0.6-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:46:10.961009Z","iopub.execute_input":"2024-03-29T03:46:10.961483Z","iopub.status.idle":"2024-03-29T03:46:27.825915Z","shell.execute_reply.started":"2024-03-29T03:46:10.961448Z","shell.execute_reply":"2024-03-29T03:46:27.824137Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/langchain-moonshot-0-0-6/langchain_moonshot-0.0.6-py3-none-any.whl\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-moonshot==0.0.6) (0.1.36)\nCollecting openai<2.0.0,>=1.10.0 (from langchain-moonshot==0.0.6)\n  Downloading openai-1.14.3-py3-none-any.whl.metadata (20 kB)\nCollecting tiktoken<1,>=0.5.2 (from langchain-moonshot==0.0.6)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (0.1.37)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (8.2.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (0.27.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (4.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain-moonshot==0.0.6) (2023.12.25)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-moonshot==0.0.6) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (2.4)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (3.10.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-moonshot==0.0.6) (1.26.18)\nDownloading openai-1.14.3-py3-none-any.whl (262 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-moonshot\nSuccessfully installed langchain-moonshot-0.0.6 openai-1.14.3 tiktoken-0.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ[\"MOONSHOT_API_KEY\"] = 'sk-l6Wg4HFd1uIjU2nlxTonoqVHJ2k8Vz0UXrszBWJoXqqw1N6v'\nos.environ['MOONSHOT_API_BASE'] = \"https://api.moonshot.cn/v1\"","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:50:25.838718Z","iopub.execute_input":"2024-03-29T03:50:25.839212Z","iopub.status.idle":"2024-03-29T03:50:25.846299Z","shell.execute_reply.started":"2024-03-29T03:50:25.839168Z","shell.execute_reply":"2024-03-29T03:50:25.844743Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Play chat","metadata":{}},{"cell_type":"code","source":"import os\nimport langchain\nfrom langchain_moonshot import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\nllm = ChatOpenAI(model_name=\"moonshot-v1-8k\")\nprint('API_BASE: %s' % llm.openai_api_base)\nprint('PROXY: %s' % llm.openai_proxy)\nprint('API_KEY: %s' % llm.openai_api_key)\nprint('Model: %s' % llm.model_name)\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are world class technical documentation writer.\"),\n    (\"user\", \"{input}\")\n])\n\noutput_parser = StrOutputParser()\n\nchat_chain = prompt | llm | output_parser\n\nresp = chat_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\nprint(resp)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:46:27.839227Z","iopub.execute_input":"2024-03-29T03:46:27.839753Z","iopub.status.idle":"2024-03-29T03:46:39.416354Z","shell.execute_reply.started":"2024-03-29T03:46:27.839706Z","shell.execute_reply":"2024-03-29T03:46:39.414842Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"API_BASE: https://api.moonshot.cn/v1\nPROXY: \nAPI_KEY: **********\nModel: moonshot-v1-8k\nAs a language model, Langsmith can assist with software testing in a number of ways:\n1. Test case generation: Langsmith can help generate test cases by providing input values and expected outcomes based on the software requirements and specifications.\n2. Test data creation: Langsmith can be used to create test data in various formats such as CSV, JSON, and XML, which can be used for testing the software.\n3. API testing: Langsmith can help design and execute API tests by generating API calls and validating the responses.\n4.UI testing: Langsmith can assist in creating test scripts for UI testing using tools like Selenium, by generating test cases based on the UI design and requirements.\n5. Performance testing: Langsmith can help in creating performance testing scenarios, by generating load and stress tests based on the expected user load and usage patterns.\n6. Test reporting: Langsmith can assist in generating test reports by summarizing test results and highlighting any failed test cases or errors.\nOverall, Langsmith can significantly reduce the time and effort required for testing, while also improving the quality and accuracy of the testing process.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Play documents","metadata":{}},{"cell_type":"code","source":"from langchain_moonshot import OpenAIClone\nfrom pathlib import Path\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nfrom langchain_core.documents import Document\n\nclient = OpenAIClone()\n\nfile_object = client.files.create(file=Path(\"/kaggle/input/optimizers/Deep Optimizers.pdf\"), purpose=\"file-extract\")\nfile_content = client.files.content(file_id=file_object.id).text\ntext_splitter = RecursiveCharacterTextSplitter()\ndocuments = text_splitter.split_documents([Document(file_content)])\n[print(document) for document in documents]","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:46:39.419844Z","iopub.execute_input":"2024-03-29T03:46:39.420410Z","iopub.status.idle":"2024-03-29T03:46:42.711616Z","shell.execute_reply.started":"2024-03-29T03:46:39.420361Z","shell.execute_reply":"2024-03-29T03:46:42.710141Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"page_content='{\"content\":\"深度学习优化器 Optimizer-SGD、mSGD、AdaGrad、\\\\nRMSProp、Adam、AdamW\\\\nOptimizer 优化\\\\n⚫ 学习率 learning rate : α\\\\n⚫ 防止除 0 的截断参数 : ϵ\\\\n⚫ t 时刻的参数 : Wt\\\\n⚫ t 时刻的梯度： gt\\\\n⚫ t 时刻的神经网络 : f ( x ; Wt )\\\\n⚫ t 时刻的梯度 gt 的一阶动量 : mt\\\\n⚫ t 时刻的梯度 gt 的二阶动量 : vt\\\\n⚫ 一阶动量历史权重 : β1\\\\n⚫ 二阶动量历史权重 : β2\\\\n⚫ 权重衰减项权重： λ\\\\n文章目录\\\\n深度学习优化器 Optimizer-SGD、mSGD、AdaGrad、RMSProp、Adam、AdamW\\\\nOptimizer 优化\\\\n文章目录\\\\n1 SGD\\\\n2 mSGD\\\\n\\\\n1 SGD\\\\nSGD(Stochastic Gradient Descent)随机梯度下降算法，在深度学习中是一个最基\\\\n础的优化算法，相比于传统凸优化所使用的梯度下降算法 GD，SGD 是在一个\\\\nmini-batch 中进行的。\\\\n公式如下：\\\\ngt = ∇ f ( x ; Wt − 1 )\\\\nWt = Wt−1 − αgt\\\\n即计算一个 mini-batch 中的损失函数的梯度，之后根据学习率进行更新，SGD\\\\n可能存在的问题是，更新幅度与梯度线性相关，一方面网络不同层之间参数数值\\\\n分布可能很不一致，这导致学习率的选择困难，不同层之间的更新速度不一致；\\\\n另一方面，不利于摆脱局部极小值，SGD 对于局部极小值的摆脱能力来源于\\\\nStochastic，即 mini-batch 中的样本随机，而非 GD 的全局选择，给予了一定的\\\\n摆脱能力。\\\\n2 mSGD\\\\nmSGD(Moving Average SGD)是 SGD 的改进算法，在 SGD 的基础上引入了动量，\\\\n从而平滑了参数的更新，并且给予了一定摆脱局部极小值的能力。\\\\n公式如下：\\\\ngt = ∇ f ( x ; Wt−1 )\\\\nmt = β1 mt−1 + ( 1 − β1 ) gt\\\\nWt = Wt−1 − αmt\\\\n即使参数到达了一个局部最小值点，由于动量 mt 的存在，类似于惯性，优化参\\\\n\\\\n数会冲过一部分的局部极小值或者鞍点。\\\\n3 AdaGrad\\\\nAdaGrad(Adaptive Gradient)算法是一种自适应学习率的算法，其根据历史梯度\\\\n平方和的大小，动态调整学习率，使得学习率逐渐下降。\\\\n公式如下：\\\\ngt = ∇ f ( x ; Wt−1 )\\\\nWt = Wt−1 − 𝛼\\\\n𝑔𝑡\\\\n√∑ 𝑔𝑖2 𝑡 𝑖=1 +ϵ\\\\nAdaGrad 根据过往的梯度平方和动态调整学习率，其优点是学习率自适应，缺点\\\\n是学习率单调下降，且受极易历史极端梯度大小影响，可能导致后续学习率过小，\\\\n无法跳出局部极小值。\\\\n4 RMSProp\\\\nRMSProp(Root Mean Square Propagation)算法是对 AdaGrad 的改进，引入\\\\nmomentum，使得学习率下降更加平滑，不易受到极端梯度的影响。\\\\n公式如下：\\\\ngt = ∇ f ( x ; Wt−1 )\\\\nvt = β2 vt−1 + ( 1 − β2 ) gt\\\\n2\\\\nWt = Wt−1 − 𝛼\\\\n𝑔𝑡\\\\n√𝑣𝑡+𝜖\\\\nRMSRrop 改进了 AdaGrad，也为 Adamting 算法提供了基础。\\\\n5 Adam\\\\n\\\\nAdam(Adaptive Momentum)算法身上明显沿用了 RMSProp 和 mSGD 的优点，同\\\\n时结合了动量与自适应学习率，其同时使用了一阶动量和二阶动量，使得 Adam\\\\n算法在收敛速度上优于 RMSProp，且具有较好的自适应性。\\\\n且针对，一阶动量和二阶动量的初始化问题，若初始化为 0，则需要很长时间才\\\\n能累计达到一个基本的学习率，因此 Adam 算法采用了一个随时间变化的补偿\\\\n项，使得一阶动量在刚开始时具有更大的值，且在后期逐渐衰减。\\\\n公式如下：\\\\ngt = ∇ f ( x ; Wt−1 )\\\\nmt = β1 mt−1 + ( 1 − β1 ) gt\\\\nvt = β2 vt−1 + ( 1 − β2 ) gt\\\\n2\\\\n𝑚𝑡 ̂ = 𝑚𝑡\\\\n1 − 𝛼?1\\\\n𝑡\\\\n𝑣𝑡̂ = 𝑣𝑡\\\\n1 − 𝛼?2\\\\n𝑡\\\\nWt = Wt−1 − 𝛼\\\\n𝑚𝑡 ̂\\\\n√𝑣𝑡 ̂+𝜖\\\\n可以看到 Adam 同时采用了一阶动量和二阶动量，并且采用了\\\\n1\\\\n1+𝛽𝑡 的形式对于\\\\n动量进行补偿，从而有着极强的自适应能力，是如今最常用的优化算法之一。\\\\n6 AdamW\\\\nAdamW 算法是对 Adam 算法的纠错，其引入了权重衰减(weight decay)，在过\\\\n往的 Adam 算法中，面对有着正则项的损失函数时，往往对于正则项的处理为第\\\\n一步 gt中：\\\\nA d a m 处理 ( 错误 ) ： gt = ∇ f ( x ; Wt−1 ) + 2 λ Wt−1\\\\n\\\\n而 AdamW 算法中，修正了这一错误，将正则项在最后一步权重更新时进行处理，\\\\n即 weight decay 不参与动量计算，公式为：\\\\nWt = Wt−1 − α(\\\\n𝑚𝑡 ̂\\\\n√𝑣𝑡 ̂+𝜖 + 2 λ Wt−1 )\\\\n7 总结\\\\n以上就是最常用的优化器 SGD、mSGD、AdaGrad、RMSProp、Adam、AdamW\\\\n的总结，其中 AdamW 算法是 Adam 算法的改进，SGD 在 CNN 中还有不错的发\\\\n挥，但在 Transformer 中却效果一般，如今 Adam 和 AdamW 算法在 Transformer\\\\n模型中有着更为广泛的应用，如 Llama、OPT、GPT 等，即使还有一些新的如 Lion\\\\n等优化器，但大体上了解以上优化器就足够了。\",\"file_type\":\"application/pdf\",\"filename\":\"Deep Optimizers.pdf\",\"title\":\"\",\"type\":\"file\"}'\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[None]"},"metadata":{}}]},{"cell_type":"markdown","source":"Set up vector database","metadata":{}},{"cell_type":"code","source":"from langchain_moonshot import OpenAIEmbeddings\nembeddings = OpenAIEmbeddings()\n\nfrom langchain_community.vectorstores import FAISS\n# vector = FAISS.from_documents(documents, embeddings)  # TODO Investigate its logic","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:46:42.713225Z","iopub.execute_input":"2024-03-29T03:46:42.713550Z","iopub.status.idle":"2024-03-29T03:46:42.764605Z","shell.execute_reply.started":"2024-03-29T03:46:42.713523Z","shell.execute_reply":"2024-03-29T03:46:42.763050Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Chain multiple documents","metadata":{}},{"cell_type":"code","source":"from langchain.chains.combine_documents import create_stuff_documents_chain\n\nprompt = ChatPromptTemplate.from_template(\n    \"\"\"\n    Answer the following question based only on the provided context:\n\n    <context>\n    {context}\n    </context>\n    \n    Question: {input}\n    \"\"\"\n    )\n\n# Create a chain for passing a list of Documents to a model.\ndocument_chain = create_stuff_documents_chain(llm, prompt)  # llm | prompt","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:46:42.767389Z","iopub.execute_input":"2024-03-29T03:46:42.767918Z","iopub.status.idle":"2024-03-29T03:46:42.879022Z","shell.execute_reply.started":"2024-03-29T03:46:42.767871Z","shell.execute_reply":"2024-03-29T03:46:42.877459Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Summarize documents","metadata":{}},{"cell_type":"code","source":"from langchain_core.documents import Document\n\nsummary = document_chain.invoke(\n    {\n        \"input\": \"What about the types of optimizers?\",\n        \"context\": [Document(page_content=\"Many optimizers are available for us.\")]\n    }\n)\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2024-03-29T03:46:42.882428Z","iopub.execute_input":"2024-03-29T03:46:42.882965Z","iopub.status.idle":"2024-03-29T03:47:04.859767Z","shell.execute_reply.started":"2024-03-29T03:46:42.882933Z","shell.execute_reply":"2024-03-29T03:47:04.858293Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Based on the provided context, we cannot provide specific information about the types of optimizers, as there is no detail given. However, in general, optimizers are software tools or algorithms designed to improve the performance, efficiency, or accuracy of a system or process. There are various types of optimizers, such as:\n\n1. Mathematical optimizers: These are algorithms used to find the optimal solution to mathematical problems, such as linear programming, nonlinear programming, and integer programming.\n\n2. Data optimizers: These tools are used to optimize data storage, retrieval, and processing in databases, data warehouses, and big data systems.\n\n3. Compiler optimizers: These are components of compilers that improve the performance and efficiency of the generated machine code by applying various optimization techniques, such as dead code elimination, loop unrolling, and code inlining.\n\n4. Network optimizers: These tools help in optimizing network traffic, routing, and bandwidth usage to enhance the overall performance and reliability of communication networks.\n\n5. Machine learning optimizers: These algorithms are used to find the best set of parameters for a machine learning model by minimizing or maximizing a given objective function, such as gradient descent, stochastic gradient descent, and conjugate gradient methods.\n\n6. Energy optimizers: These tools help in optimizing energy consumption in various systems, such as buildings, industrial processes, and smart grids, by controlling and adjusting the usage of resources like heating, cooling, and lighting.\n\nPlease note that this is a general overview of some optimizer types. To provide more specific information, additional context would be required.\n","output_type":"stream"}]}]}